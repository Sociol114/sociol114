---
title: "Problem Set 4: Statistical Learning"
---

**Due: 5pm on Friday, Feb 28.**

This problem set has not yet been posted.

class website page is a possibility for data here. Effect of college on subjective social class.

```{r}
knitr::opts_chunk$set(eval = FALSE)
```

**NOTE:** This problem set will be updated to explicitly involve statistical learning with more guidance, as well as some causal inference.

::: {.callout-note}
Want to see how you'll be evaluated? Check out the [rubric](https://docs.google.com/forms/d/e/1FAIpQLSfE9cKW1TdZvmNH7AUTdzL2Fd3vnQicKVECc7qW2_S4civJpg/viewform?usp=sharing)
:::

Student identifer: [type your anonymous identifier here]

- Use this [.qmd template](../assets/pset3/pset3.qmd) to complete the problem set
- In Canvas, you will upload the PDF produced by your .qmd file
- Put your identifier above, not your name! We want anonymous grading to be possible

This problem set is connected to the [PSID Income Prediction Challenge](../topics/prediction.qmd) from discussion.

## NOTES

Goals are

* Sample split
* Estimate MSE

* Parametric g-formula outcome

* there is no ML algorithm on this problem set nor any IPTW

Would be nice to have a nonlinear confounder and a binary treatment.


```{r}
library(tidyverse)
# taken from principal stratification 
data <- readRDS("../data_raw/motherhood.RDS") |>
  select(
    treated, employed, age = age_2, sex, race, employed_baseline, 
    educ, marital, fulltime, tenure, experience,
    weight = w
  ) |>
  na.omit()
```

# Part 1: Model employment among new mothers by age

(note: linear and logistic are almost identical)

```{r}

# new parents vs never parents, by sex?

data |>
  ggplot(aes(x = age, y = as.numeric(employed), color = treated)) +
  geom_smooth(method = "lm") +
  facet_wrap(~sex)

# Do just among women.
# What is MSE of model that interacts age * treated? What is MSE of model that does not?
```

# Part 2: Model selection by sample splitting

# Part 3: Causal effect of motherhood




```{r}
new_mothers <- data |>
  filter(treated)

summary(lm(employed ~ age * sex, data = new_mothers))

new_mothers |>
  ggplot(aes(x = age, y = as.numeric(employed), color = sex)) +
  geom_smooth()

fit_linear <- lm(employed ~ age, data = new_mothers)
fit_logistic <- glm(employed ~ age, data = new_mothers, family = binomial)
fit_loess <- loess(employed ~ age, data = new_mothers)

new_mothers |>
  mutate(
    linear = predict(fit_linear),
    logistic = predict(fit_logistic, type = "response"),
    loess = predict(fit_loess, type = "response")
  ) |>
  select(age, linear, logistic, loess) |>
  pivot_longer(cols = -age) |>
  ggplot(aes(x = age, y = value, color = name)) +
  geom_line()

new_mothers |>
  group_by(age) |>
  summarize(employed = weighted.mean(employed, w = weight)) |>
  ggplot(aes(x = age, y = employed)) +
  geom_point()
```

Part 1) Parametric g-formula

```{r}
fit <- lm(employed ~ treated * sex * (age + race + employed_baseline + educ + marital + fulltime + tenure + experience),
          data = data)

coef(fit)
coef(fit_ridge, s = "lambda.1se")




fit_ridge <- cv.glmnet(
  x = model.matrix(
    ~ treated * sex * (age + race + employed_baseline + educ + marital + fulltime + tenure + experience),
    data = data
  ),
  y = data$employed,
  alpha = 0
)



# Parametric g-formula
data |>
  mutate(yhat1 = predict(fit, newdata = data |> mutate(treated = TRUE)),
         yhat0 = predict(fit, newdata = data |> mutate(treated = FALSE))) |>
  group_by(sex) |>
  summarize(average_effect = mean(yhat1 - yhat0))
```

Part 2) Parametric g-formula with machine learning

```{r}
women <- data |>
  filter(sex == "Women")
fit <- causal_forest(
  X = model.matrix(
    ~ age + race + employed_baseline + educ + marital + fulltime + tenure + experience,
    data = women
  ),
  W = women$treated,
  Y = women$employed
)

average_treatment_effect(fit)



```

Outtakes: Too hard
```{r}
# Inverse probability weighting
fit_a <- glm(
  treated ~ sex * (age + race + employed_baseline + educ + marital + fulltime + tenure + experience),
  data = data
)

data |>
  mutate(
    pscore = predict(fit_a, type = "response"),
    pscore = case_when(treated ~ pscore,
                       !treated ~ 1 - pscore)
  ) |>
  group_by(sex, treated) |>
  summarize(estimate = weighted.mean(employed, w = 1 / pscore)) |>
  pivot_wider(names_from = "treated", values_from = "estimate") |>
  mutate(average_effect = `TRUE` - `FALSE`)

```


```{r}
data |>
  ggplot(aes(x = g2_log_income, y = as.numeric(g3_educ == "College"), color = g2_educ == "College")) +
  geom_smooth()
```

## Prediction challenge

```{r}
data <- read_csv("data_raw/income_challenge/for_students/learning.csv") |>
  mutate(across(contains("educ"), \(x) factor(x,levels = c("Less than high school","High school","Some college","College"))))
```

## 1. OLS prediction

Predict `g3_log_income` given all other variables by OLS.

```{r}
fit <- lm(
  g3_log_income ~ race + sex + 
    g1_log_income + g2_log_income + 
    g1_educ + g2_educ*g3_educ,
  data = data
)
```

Estimate the average causal effect of college vs high school.

```{r}
data |>
  mutate(yhat1 = predict(fit, newdata = data |> mutate(g3_educ = "College")),
         yhat0 = predict(fit, newdata = data |> mutate(g3_educ = "High school"))) |>
  summarize(ate = mean(yhat1 - yhat0))
```

Estimate within subgroups of parents' education

```{r}
data |>
  mutate(yhat1 = predict(fit, newdata = data |> mutate(g3_educ = "College")),
         yhat0 = predict(fit, newdata = data |> mutate(g3_educ = "High school"))) |>
  group_by(g2_educ) |>
  summarize(ate = mean(yhat1 - yhat0))
```

## 2. Causal forest prediction

```{r}
library(grf)
```

```{r}

for_forest <- data |>
      filter(g3_educ %in% c("High school","College"))

fit <- causal_forest(
  X = model.matrix(
    ~ race + sex + g2_log_income + g2_educ,
    data = for_forest
  ),
  Y = for_forest$g3_log_income,
  W = for_forest$g3_educ == "College"
)

summary(fit)
average_treatment_effect(fit, target.sample = "control")



conditi

# Prepare the predictor matrix
model.matrix(fit)

X <- X0 <- X1 <- model.matrix(
  ~ race + sex + 
    g1_log_income + g2_log_income + 
    g1_educ + g2_educ*g3_educ,
  data = data
)
X1[""]

X_factual <- model.matrix(
  object = ~g3_log_income ~ race + sex,
  data = data.frame(data)
)
X_treated <- model.matrix(
  ~g3_log_income ~ race + sex + 
    g1_log_income + g2_log_income + 
    g1_educ + g2_educ*g3_educ,
  data = data |> mutate(g3_educ = "College")
)
X_untreated <- model.matrix(
  ~g3_log_income ~ race + sex + 
    g1_log_income + g2_log_income + 
    g1_educ + g2_educ*g3_educ,
  data = data |> mutate(g3_educ = "High school")
)

fit <- regression_forest(
  X = 
)
```







```{r}
data |>
  group_by(g3_educ) |>
  summarize(y = mean(g3_log_income)) |>
  mutate(
    g3_educ = factor(g3_educ),
    g3_educ = fct_relevel(g3_educ, "Less than high school","High school","Some college","College")
  ) |>
  ggplot(aes(x = g3_educ, y = y)) +
  geom_point() +
  scale_y_continuous(labels = function(x) scales::label_dollar()(exp(x)))
```

```{r}
data |>
  mutate(
    yhat_factual = predict(fit_ols),
    yhat_counterfactual = predict(fit_ols, newdata = data |> mutate(g3_educ = "College"))
  ) |>
  select(g2_log_income, starts_with("yhat")) |>
  pivot_longer(cols = -g2_log_income) |>
  ggplot(aes(x = g2_log_income, y = value, color = name)) +
  geom_line()
```



# Model g3_log_income given g2_log_income

```{r}
data |>
  ggplot(aes(x = g2_log_income, y = g3_log_income)) +
  geom_point() +
  geom_smooth(method = "lm", se = F) +
  facet_wrap(~ g3_educ)

fit <- lm(g3_log_income ~ g3_educ + g2_log_income + race + sex, data = data)





fit <- lm(g3_log_income ~ g2_log_income + g1_log_income, data = data)

```

## Income Prediction Challenge

**Collaboration note.** This question is an individual write-up connected to your group work from discussion. We expect that the approach you tell us might be the same as that of your other group members, but your answers to these questions should be in your own words.

**1.1 (5 points)** How did you choose the predictor variables you used? Correct answers might be entirely conceptual, entirely data-driven, or a mixture of both.

**1.2 (5 points)** What learning algorithms or models did you consider, and how did you choose one? Correct answers might be entirely conceptual, entirely data-driven, or a mixture of both.

**1.3 (20 points)** Split the `learning` data randomly into `train` and `test`. Your split can be 50-50 or another ratio. Learn in the `train` set and make predictions in the `test` set. What do you estimate for your out-of-sample mean squared error? There is no written answer here; the answer is the code and result.

## Grad. Machine learning versus statistics

> This question is required for grad students. It is optional for undergrads, and worth no extra credit.

**20 points.** This question is about the relative gain in this problem as we move from no model to a statistical model to a machine learning model.

First, use your `train` set to estimate 3 learners and predict in your `test` set.

a) No model. For every `test` observation, predict the mean of the `train` outcomes
b) Ordinary Least Squares. Choose a set of predictors $\vec{X}$. For every `test` observation, predict using a linear model `lm()` fit to the `train` set with the predictors $\vec{X}$.
c) Machine learning. Use the same set of predictors $\vec{X}$. For every `test` observation, predict using a machine learning model fit to the `train` set with the predictors $\vec{X}$. Your machine learning model could be a Generalized Additive Model (`gam()`), a decision tree (`rpart()`), or some other machine learning approach.

Report your out-of-sample mean squared error estimates for each approach. How did mean squared error change from (a) to (b)? From (b) to (c)?

Interpret what you found. To what degree does machine learning improve predictability, beyond what can be achieved by Ordinary Least Squares?
